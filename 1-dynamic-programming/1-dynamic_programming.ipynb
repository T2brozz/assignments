{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51f3ab5-22c7-4ead-9169-494e12e73c1a",
   "metadata": {},
   "source": [
    "# Assignment 1: Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0361ad-79a6-4492-b080-ee8bcf8ca4de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) Edit Distances\n",
    "\n",
    "Implement the [Hamming](https://en.wikipedia.org/wiki/Hamming_distance) and [Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance) (edit) distances and compute them for the for the following word pairs.\n",
    "It may help to compute them by hand first.\n",
    "\n",
    "<img src = \"./assets/97090.jpg\" width=\"33%\" /> <img src = \"./assets/97222.jpg\" width=\"33%\" /> <img src = \"./assets/97669.jpg\" width=\"33%\" />\n",
    "\n",
    "Aside from computing the distance (which is a scalar), do the backtrace and compute the edit transcript (and thus alignment).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b947e856-5284-4cf2-922f-c44268c365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_PAIRS = [\n",
    "    (\"GCGTATGAGGCTAACGC\", \"GCTATGCGGCTATACGC\"),\n",
    "    (\"kühler schrank\", \"schüler krank\"),\n",
    "    (\"the longest\", \"longest day\"),\n",
    "    (\"nicht ausgeloggt\", \"licht ausgenockt\"),\n",
    "    (\"gurken schaben\", \"schurkengaben\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f504ef-3822-44fe-986f-88b4ca791017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(s1: str, s2: str) -> int:\n",
    "    \"\"\"\n",
    "    Compute the hamming distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int.\n",
    "    \"\"\"\n",
    "    # Hint: Think about how you can deal with unequal word lengths.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    distance = 0\n",
    "    #assert len(s1) == len(s2), \"Strings must have equal length\"\n",
    "    for i in range(max(len(s1), len(s2))):\n",
    "\n",
    "        if i>=len(s1) or i >= len(s2) or  s1[i] != s2[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a59e5d-2bcc-40d6-b3b8-c24d886bc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
      "hamming('kühler schrank', 'schüler krank') = 13\n",
      "hamming('the longest', 'longest day') = 11\n",
      "hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
      "hamming('gurken schaben', 'schurkengaben') = 14\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist = hamming(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"hamming('{}', '{}') = {}\".format(\n",
    "        wordpair[0], wordpair[1], dist\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
    "# hamming('kühler schrank', 'schüler krank') = 13\n",
    "# hamming('the longest', 'longest day') = 11\n",
    "# hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
    "# hamming('gurken schaben', 'schurkengaben') = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebe3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9791159e-0511-44d1-9e39-481942835d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def levenshtein(s1: str, s2: str, cost={'m': 0, 's': 1, 'i': 1, 'd': 1}) -> (int, str):\n",
    "    \"\"\"\n",
    "    Compute the levenshtein (edit) distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int and edit transcript as string.\n",
    "    \"\"\"\n",
    "    # Hint: The probably most intuitive approach is bottom-up.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    #print(\"s1: \", s1, \"s2: \", s2)\n",
    "    costs = np.zeros((len(s1)+1, len(s2)+1), dtype=int) # kosten matrix\n",
    "\n",
    "    #erste Zeile und spalte \n",
    "    costs[0, 1:] = range(1, len(s2) + 1)\n",
    "    costs[1:, 0] = range(1, len(s1) + 1)\n",
    "\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                delta = cost['m']\n",
    "            else:\n",
    "                delta = cost['s']\n",
    "            costs[i, j] = min(costs[i-1, j] + cost['d'], costs[i, j-1] + cost['i'], costs[i-1, j-1] + delta)\n",
    "\n",
    "    transcript = \"\"\n",
    "    #backtrack\n",
    "    i = len(s1)\n",
    "    j = len(s2)\n",
    "    while i > 0 and j > 0:\n",
    "        if s1[i-1] == s2[j-1]:\n",
    "            transcript += \"m\"\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif costs[i, j] == costs[i-1, j] + cost['d']:\n",
    "            transcript += \"d\"\n",
    "            i -= 1\n",
    "        elif costs[i, j] == costs[i, j-1] + cost['i']:\n",
    "            transcript += \"i\"\n",
    "            j -= 1\n",
    "        else:\n",
    "            transcript += \"s\"\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    #print(costs)\n",
    "    return costs[-1, -1], transcript[::-1]\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b794add6-0ee0-4a64-a79f-4b0e68d3a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
      "levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmsddmmmm)\n",
      "levenshtein('the longest', 'longest day') = 8 (mmmmmmmiiii)\n",
      "levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
      "levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmsdddmmmm)\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist, transcript = levenshtein(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"levenshtein('{}', '{}') = {} ({})\".format(\n",
    "        wordpair[0], wordpair[1], dist, transcript\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
    "# levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmsddmmmm)\n",
    "# levenshtein('the longest', 'longest day') = 8 (ddddmmmmmmmiiii)\n",
    "# levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
    "# levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmsdddmmmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84084e8a-f48d-45a6-8f8d-199981dc0aa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Basic Spelling Correction using Edit Distance\n",
    "\n",
    "For spelling correction, we will use prior knowledge, to put _some_ learning into our system.\n",
    "\n",
    "The underlying idea is the _Noisy Channel Model_, that is: The user _intends_ to write a word `w`, but through some noise in the process, happens to type the word `x`.\n",
    "\n",
    "The correct word $\\hat{w}$ is that word, that is a valid candidate and has the highest probability:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\DeclareMathOperator*{\\argmax}{argmax}\n",
    "\\hat{w} & = & \\argmax_{w \\in V} P(w | x) \\\\\n",
    "        & = & \\argmax_{w \\in V} \\frac{P(x|w) P(w)}{P(x)} \\\\\n",
    "        & = & \\argmax_{w \\in V} P(x|w) P(w)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "1. The candidates $V$ can be obtained from a _vocabulary_.\n",
    "2. The probability $P(w)$ of a word $w$ can be _learned (counted) from data_.\n",
    "3. The probability $P(x|w)$ is more complicated... It could be learned from data, but we could also use a _heuristic_ that relates to the edit distance, e.g. rank by distance.\n",
    "\n",
    "You may use [Peter Norvig's count_1w.txt](http://norvig.com/ngrams/) file, [local mirror](res/count_1w.tar.bz2).\n",
    "Note that it may help to restrict to the first 10k words to get started.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7190fb5-93c5-456b-835b-32a73d0f3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    \"pirates\",    # in-voc\n",
    "    \"pirutes\",    # pirates?\n",
    "    \"continoisly\",  # continuosly?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d9c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/yannes/Documents/seqlrn-assignments/.venv/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce0ead32-59de-42c4-b488-a56001931fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Prepare the l\n",
    "\n",
    "### YOUR CODE HERE\n",
    "words= pd.read_csv(\"./data/count_1w.txt\", sep=\"\\t\", header=None, names=[\"word\",\"count\"],dtype={\"word\":str,\"count\":int})\n",
    "words= words.head(10000)\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecda371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>varieties</td>\n",
       "      <td>5057493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>arbor</td>\n",
       "      <td>5057261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>mediawiki</td>\n",
       "      <td>5056973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>configurations</td>\n",
       "      <td>5056310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>poison</td>\n",
       "      <td>5056083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word        count\n",
       "0                the  23135851162\n",
       "1                 of  13151942776\n",
       "2                and  12997637966\n",
       "3                 to  12136980858\n",
       "4                  a   9081174698\n",
       "...              ...          ...\n",
       "9995       varieties      5057493\n",
       "9996           arbor      5057261\n",
       "9997       mediawiki      5056973\n",
       "9998  configurations      5056310\n",
       "9999          poison      5056083\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f88150c8-3d00-483e-8682-1f6720d2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest(w: str, dist_fn, max_cand=5) -> list:\n",
    "    \"\"\"\n",
    "    Compute suggestions for spelling correction using edit distance.\n",
    "    \n",
    "    Arguments:\n",
    "    w: Word in question.\n",
    "    dist_fn: Distance function to use (e.g. levenshtein).\n",
    "    max_cand: Maximum number of suggestions.\n",
    "\n",
    "    Returns a list of tuples (word, dist, score) sorted by score and distance.\n",
    "    \"\"\"\n",
    "    mywords= pd.DataFrame(words)\n",
    "    ### YOUR CODE HERE\n",
    "    mywords[\"sim\"]= 0.0\n",
    "    for i in range(len(mywords)):\n",
    "        mywords.at[i, \"sim\"], _ = dist_fn(w, str(mywords.at[i, \"word\"]))\n",
    "    \n",
    "        #mywords.at[i, \"score\"]= float(mywords.at[i, \"count\"]) / float(mywords.at[i, \"sim\"]+1)\n",
    "    mywords = mywords.sort_values(by=[ \"sim\"], ascending= True)\n",
    "    return  mywords.head(max_cand)\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f5490ca-969c-4a93-aaf0-8cdb3433ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pirates           word    count  sim         score\n",
      "8415   pirates  6531487  0.0  6.531487e+06\n",
      "7878  emirates  7182004  2.0  2.394001e+06\n",
      "8351   phrases  6596622  2.0  2.198874e+06\n",
      "pirutes          word     count  sim         score\n",
      "8415  pirates   6531487  1.0  3.265744e+06\n",
      "6816  viruses   8786573  2.0  2.928858e+06\n",
      "831   minutes  96242209  2.0  3.208074e+07\n",
      "continoisly               word    count  sim         score\n",
      "9348  continuously  5610397  2.0  1.870132e+06\n",
      "8861    continuity  6045562  3.0  1.511390e+06\n",
      "9705   continually  5278721  3.0  1.319680e+06\n"
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with levenshtein distance?\n",
    "\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=levenshtein, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))\n",
    "\n",
    "### EXPECTED\n",
    "### Notice: your scores may vary!\n",
    "# pirates [('pirates', 0, -11.408058827802126)]\n",
    "# pirutes [('pirates', 1, -11.408058827802126), ('minutes', 2, -8.717825438953103), ('viruses', 2, -11.111468702571859)]\n",
    "# continoisly [('continously', 1, -15.735337826575178), ('continuously', 2, -11.560071979871001), ('continuosly', 2, -17.009283000138204)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa2e00-a1dd-46e5-90c0-2f3eea3cb031",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- How would you modify the implementation so that it works fast for large lexica (eg. the full file above)?\n",
    "- How would you modify the implementation so that it works \"while typing\" instead of at the end of a word?\n",
    "- How do you handle unknown/new words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183c2b3-7cee-420e-bb08-5748dbfed5dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3) Needleman-Wunsch: Keyboard-aware Auto-Correct\n",
    "\n",
    "In the parts 1 and 2 above, we applied uniform cost to all substitutions.\n",
    "This does not really make sense if you look at a keyboard: the QWERTY layout will favor certain substitutions (eg. _a_ and _s_), while others are fairly unlikely (eg. _a_ and _k_).\n",
    "\n",
    "Implement the [Needleman-Wunsch algorithm](https://en.wikipedia.org/wiki/Needleman–Wunsch_algorithm) which is very similar to the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance), however it doesn't _minimize the cost_ but _maximizes the similarity_.\n",
    "For a good measure of similarity, implement a metric that computes a meaningful weight for a given character substitution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "001fe3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23709626-6af8-41ae-b713-f0d8c7b117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# QWERTY key positions (row, col)\n",
    "keyboard = {\n",
    "    'q': (0, 0), 'w': (0, 1), 'e': (0, 2), 'r': (0, 3), 't': (0, 4), 'y': (0, 5), 'u': (0, 6), 'i': (0, 7), 'o': (0, 8), 'p': (0, 9),\n",
    "    'a': (1, 0), 's': (1, 1), 'd': (1, 2), 'f': (1, 3), 'g': (1, 4), 'h': (1, 5), 'j': (1, 6), 'k': (1, 7), 'l': (1, 8),\n",
    "    'z': (2, 0), 'x': (2, 1), 'c': (2, 2), 'v': (2, 3), 'b': (2, 4),  'n': (2, 5), 'm': (2, 6)\n",
    "}\n",
    "\n",
    "def keyboard_sim(c1: str, c2: str) -> float:\n",
    "    \"\"\"abstand zwischen zwei chats im qwerty layout\"\"\"\n",
    "    c1, c2 = c1.lower(), c2.lower()\n",
    "    if c1 not in keyboard or c2 not in keyboard:\n",
    "        return 0.0\n",
    "    pos1, pos2 = keyboard[c1], keyboard[c2]\n",
    "    d = math.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "    return (1 - (d / 9.5))*20\n",
    "# higher is closer \n",
    "\n",
    "def nw(s1: str, s2: str, d: float, sim_fn) -> float:\n",
    "    \"\"\"\n",
    "    Apply needleman-wunsch algorithm.\n",
    "    \n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    d: Gap penalty score.\n",
    "    sim_fn: Similarity function to use.\n",
    "\n",
    "    Returns the score as float.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    D = np.zeros((len(s1) + 1, len(s2) + 1), dtype=int)\n",
    "# for the empty word, costs match the length of the other string\n",
    "    D[0, 1:] = range(1, len(s2) + 1); D[0, 1:] *= d\n",
    "    D[1:, 0] = range(1, len(s1) + 1); D[1:, 0] *= d\n",
    "    for i in range(1, len(s1)):\n",
    "        for j in range(1, len(s2)):\n",
    "            cs = D[i-1, j-1] + sim_fn(s1[i], s2[j])\n",
    "            cd = D[i-1, j] + d\n",
    "            ci = D[i, j-1] + d\n",
    "            D[i,j] = max(cs, cd, ci)\n",
    "            #print(D)\n",
    "\n",
    "    return D[len(s1)-1][len(s2)-1]    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def nw_based_dist(s1: str, s2: str) -> (int, str):\n",
    "    \"\"\"\n",
    "    Compute the needleman-wunsch distance between two strings.\n",
    "    \n",
    "    Arguments:\n",
    "    s1d: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    \n",
    "    Returns the distance as int and <unsupported> string.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return nw(s1, s2, -1, keyboard_sim), \"<unsupported>\"\n",
    "    # Hint: return dist, \"<unsupported>\"\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71cbd5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw(\"halo\", \"helo\",-1, keyboard_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f510005-f578-4afa-99a3-9a389fd86069",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXAMPLES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# How does your suggest function behave with nw and a keyboard-aware similarity?\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# irgendwie kommt da bullshit raus warum auch immer...\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mEXAMPLES\u001b[49m:\n\u001b[32m      4\u001b[39m     suggestions = suggest(w=word, dist_fn=nw_based_dist, max_cand=\u001b[32m3\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(word, suggestions))\n",
      "\u001b[31mNameError\u001b[39m: name 'EXAMPLES' is not defined"
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with nw and a keyboard-aware similarity?\n",
    "# irgendwie kommt da bullshit raus warum auch immer...\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=nw_based_dist, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63b759-ba2d-4ad1-9011-f0067e968688",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- What could be better heuristics for similarity resp. cost of substitution than the one above?\n",
    "- What about capitalization, punctiation and special characters?\n",
    "- What about swipe-to-type?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
