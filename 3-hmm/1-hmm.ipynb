{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2183f50-3d39-4832-af72-42791571713d",
   "metadata": {},
   "source": [
    "# Assignment 3: Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996891f9-c12d-47bb-93f5-2f25cc60709b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) Isolated Word Recognition\n",
    "\n",
    "In this assignment, we'll be revising word recognition, this time using Hidden Markov Models (HMM).\n",
    "As with [assignment 1](https://github.com/seqlrn/assignments/tree/master/1-dynamic-programming), we'll be using the [free spoken digits](https://github.com/Jakobovski/free-spoken-digit-dataset) dataset.\n",
    "We will be using the [`pandas`](https://pandas.pydata.org/docs/) library for data handling and [`hmmlearn`](https://hmmlearn.readthedocs.io/en/latest/index.html) library for HMMs which depends on `numpy`.\n",
    "Install the `pandas` and `hmmlearn` packages in your working environment and get familiar with these modules.\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "Download Zohar Jackson's [free spoken digit](https://github.com/Jakobovski/free-spoken-digit-dataset) dataset.\n",
    "There's no need to clone, feel free to use a revision, like [v1.0.10](https://github.com/Jakobovski/free-spoken-digit-dataset/archive/refs/tags/v1.0.10.tar.gz).\n",
    "The file naming convention is `{digitLabel}_{speakerName}_{index}.wav`.\n",
    "\n",
    "### Basic Setup\n",
    "\n",
    "As you can learn from the [tutorial](https://hmmlearn.readthedocs.io/en/latest/tutorial.html#), `hmmlearn` provides us with the base implementation of Hidden Markov Models; we'll be using the `hmm.GaussianHMM`, which implements HMMs with a single Gaussian emission probability per state.\n",
    "For a starter, build a basic isolated word recognizer that uses a separate model for each digit.\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b982ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/yannes/Documents/seqlrnass/.venv/lib64/python3.12/site-packages (from hmmlearn) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /home/yannes/Documents/seqlrnass/.venv/lib64/python3.12/site-packages (from hmmlearn) (1.6.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /home/yannes/Documents/seqlrnass/.venv/lib64/python3.12/site-packages (from hmmlearn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/yannes/Documents/seqlrnass/.venv/lib64/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/yannes/Documents/seqlrnass/.venv/lib64/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
      "Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffb0527-90ea-4f0a-ab0c-40817df51dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666267-390d-402a-aae9-e3588b51c262",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 To facilitate the selection of samples for speakers and digits, consider how you can store the data within a `pandas.DataFrame`.\n",
    "\n",
    "1.2 Compute the MFCC features for the complete data set (3000 recordings; use `n_mfcc=13`).\n",
    "\n",
    "1.3 Apply per-speaker feature normalization (e.g., standardization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ee275c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 50 # recordings per speaker & digit\n",
    "DIGITS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "SPEAKERS = [\"george\", \"jackson\", \"lucas\", \"nicolas\", \"theo\", \"yweweler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9acf929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notice: a good default value is 25ms for FFT window and 10ms for hop length\n",
    "### Notice: be careful as librosa takes the number of samples as input!        \n",
    "\n",
    "def compute_features(file):\n",
    "    \"\"\"Computes the features for a recording file.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    # Compute MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "    return mfccs.T.tolist()  # Transpose to get time x features\n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def load_dataframe(input_dir):\n",
    "    \"\"\"Loads the recordings into a pandas.DataFrame.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    data= pd.DataFrame(columns=[\"speaker\", \"digit\", \"features\"])\n",
    "    for speaker in SPEAKERS:\n",
    "        for digit in DIGITS:\n",
    "            for i in range(NUM_SAMPLES):\n",
    "                file = os.path.join(input_dir, f\"{digit}_{speaker}_{i}.wav\")\n",
    "\n",
    "                if os.path.exists(file):\n",
    "                    features = compute_features(file)\n",
    "                    data = pd.concat( [data, pd.DataFrame({\"speaker\": [speaker], \"digit\": [digit], \"features\": [features]})], ignore_index=True)\n",
    "    print(f\"Loaded {len(data)} recordings\")\n",
    "    return data\n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7466a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 recordings\n",
      "Num recordings: 3000\n",
      "### george\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n",
      "### jackson\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n",
      "### lucas\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n",
      "### nicolas\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n",
      "### theo\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n",
      "### yweweler\n",
      "digit\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "4    50\n",
      "5    50\n",
      "6    50\n",
      "7    50\n",
      "8    50\n",
      "9    50\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>digit</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-301.03790283203125, 68.15388488769531, 57.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-559.0995483398438, 104.31383514404297, 50.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-504.5478820800781, 79.89419555664062, 32.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-532.5098266601562, 82.81941223144531, 48.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-475.34173583984375, 93.90748596191406, 36.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-753.287109375, 61.35637283325195, 48.667442...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-654.5306396484375, 74.78880310058594, 10.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-816.416748046875, 74.50633239746094, 58.812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-800.8235473632812, 76.26612091064453, 63.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-791.7648315429688, 71.23277282714844, 58.78...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       speaker digit                                           features\n",
       "0       george     0  [[-301.03790283203125, 68.15388488769531, 57.7...\n",
       "1       george     0  [[-559.0995483398438, 104.31383514404297, 50.5...\n",
       "2       george     0  [[-504.5478820800781, 79.89419555664062, 32.70...\n",
       "3       george     0  [[-532.5098266601562, 82.81941223144531, 48.47...\n",
       "4       george     0  [[-475.34173583984375, 93.90748596191406, 36.1...\n",
       "...        ...   ...                                                ...\n",
       "2995  yweweler     9  [[-753.287109375, 61.35637283325195, 48.667442...\n",
       "2996  yweweler     9  [[-654.5306396484375, 74.78880310058594, 10.54...\n",
       "2997  yweweler     9  [[-816.416748046875, 74.50633239746094, 58.812...\n",
       "2998  yweweler     9  [[-800.8235473632812, 76.26612091064453, 63.01...\n",
       "2999  yweweler     9  [[-791.7648315429688, 71.23277282714844, 58.78...\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIR = \"./data/recordings\"\n",
    "dataframe = load_dataframe(input_dir=INPUT_DIR)\n",
    "\n",
    "### Notice: just for test purposes\n",
    "\n",
    "print(\"Num recordings: {}\".format(len(dataframe)))\n",
    "for speaker in SPEAKERS:\n",
    "    print(\"### {}\".format(speaker))\n",
    "    data_speaker = dataframe[dataframe[\"speaker\"] == speaker]\n",
    "    print(data_speaker[\"digit\"].value_counts())\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc48991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a874064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_features(dataframe):\n",
    "    \"\"\"Trims all feature vectors in the dataframe to the minimum length.\"\"\"\n",
    "    # Get all features from the dataframe\n",
    "    features = dataframe['features'].tolist()\n",
    "\n",
    "    # Find the minimum length of features across all recordings\n",
    "    min_len = min(len(f) for f in features)\n",
    "\n",
    "    # Trim all features to the minimum length\n",
    "    trimmed_features = [f[:min_len] for f in features]\n",
    "\n",
    "    # Update the dataframe with trimmed features\n",
    "    dataframe['features'] = trimmed_features\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Apply the trimming function\n",
    "dataframe_trimmed = trim_features(dataframe=dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff776d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdataframe_trimmed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeatures\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "571a47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(dataframe):\n",
    "    \"\"\"Applies per-speaker feature normalization.\"\"\"\n",
    "    \n",
    "    # Normalize the features for each speaker\n",
    "    speakers = dataframe['speaker'].unique()\n",
    "    \n",
    "    for speaker in speakers:\n",
    "        speaker_data = dataframe[dataframe['speaker'] == speaker]\n",
    "        features = np.array(speaker_data['features'].tolist())\n",
    "        features = np.array(features)\n",
    "        mean = np.mean(features, axis=0)\n",
    "        std = np.std(features, axis=0)\n",
    "        normalized_features = (features - mean) / std\n",
    "        for i, idx in enumerate(speaker_data.index):\n",
    "            dataframe.at[idx, 'features'] = normalized_features[i].tolist()\n",
    "            \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "dataframe_w_norm = normalize_features(dataframe=dataframe_trimmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb8bb6",
   "metadata": {},
   "source": [
    "### Train and Evaluate\n",
    "\n",
    "2.1 Implement a 6-fold [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) loop for the 6 speakers to (later) figure out, which test speaker performs best/worst. That is, each speaker acts as test speaker while the others are used for training (with each possible combination).\n",
    "\n",
    "2.2 Inside the cross-validation loop, train an individual HMM with linear topology for each digit. There are several points to consider:\n",
    "\n",
    "*The [`fit`](https://github.com/hmmlearn/hmmlearn/blob/38b3cece4a6297e978a204099ae6a0a99555ec01/lib/hmmlearn/base.py#L439) expects features to be sequential in a single array with `X` as (n_train_samples, n_features). Furthermore, we need to pass the lengths of each recording into the function with`lengths` as (n_samples,):*\n",
    "\n",
    "```python\n",
    "### you can flatten the features of the train data as follows\n",
    "\n",
    "# input: [(rec_samples_1, n_feats), ..., (rec_samples_N, n_feats)]\n",
    "# output: (all_rec_samples, n_feats)\n",
    "features = [features for features in dataframe[\"features\"].values]\n",
    "flatten = np.concatenate(features, axis=0)\n",
    "\n",
    "lengths = np.array([...])\n",
    "\n",
    "# train HMM\n",
    "hmm.fit(X=flatten, lengths=lengths)\n",
    "```\n",
    "\n",
    "*For the HMM, it is necessary to choose a meaningful number of states. How many states (`n_components`) do you choose, and why?*\n",
    "\n",
    "*With respect to the used `hmmlearn` library. How can you enforce a linear topology?*\n",
    "\n",
    "*You might find that certain digits perform particularly bad; what could be a reason and how to mitigate it?*\n",
    "    \n",
    "2.3 Compute the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) for each speaker and for the overall dataset by combining the predictions of the cross-validation. You can use the [`scikit-learn`](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) library.\n",
    "\n",
    "2.4 Additional experiment: Compare the results without and with per-speaker feature normalization. How does the performance change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb30f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e903d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO:\n",
    "### 1. set the `n_components` for all digits (choose a meaningful number of states)\n",
    "\n",
    "n_comps = {i: None for i in DIGITS}\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f36c4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: \n",
    "### 1. implement the 6-fold cross-validation loop\n",
    "### 2. allocate and initialize the HMMs, one for each digit; set a linear topology\n",
    "### 3. train the HMMs using the fit method; data needs to be concatenated\n",
    "### 4. evaluate the trained models on the test speaker; how do you decide which word\n",
    "###    was spoken?\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c3e80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: \n",
    "### 1. based on the results, compute and display the confusion matrix for \n",
    "###    each test speaker \n",
    "### 2. compute and display the confusion matrix for the overall dataset\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278660a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Decoding Sequences of Digits\n",
    "\n",
    "The example above can't handle sequences of spoken digits.\n",
    "In this part of the assignment, you'll build a basic decoder that is able to decode arbitrary sequences of digits (without a prior, though).\n",
    "The `decode` method in `hmmlearn` only works for a single HMM.\n",
    "There are two ways how to solve this assignment:\n",
    "\n",
    "- Construct a \"meta\" HMM from the previously trained digit HMMs, by allowing state transitions from one digit to another; the resulting HMM can be decoded using the existing `decode` method (don't forget to re-map the state ids to the originating digit).\n",
    "\n",
    "- (Optional) Implement a real (time-synchronous) decoder using beam search. The straight-forward way is to maintain a (sorted) list of active hypotheses (ie. state history and current log-likelihood) that is first expanded and then pruned in each time step. The tricky part is at the \"end\" of a model: do you loop or expand new words?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe48a9b",
   "metadata": {},
   "source": [
    "### Generate Test Sequences\n",
    "\n",
    "3.1 Generate a few test sequences of random length in between 3 and 6 digits; use [`numpy.random.randint`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html) and be sure to also retain the digits sequence since we need to compute edit distance between reference and hypotheses later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digit_sequence(speaker_dataframe, min_digits, max_digits):\n",
    "    \"\"\"\n",
    "    Creates a sequence of spoken digits from a speaker and returns the\n",
    "    features and reference label.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eda3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notice: just for test purposes\n",
    "\n",
    "# speaker = \"george\"\n",
    "# data_george = dataframe[dataframe[\"speaker\"] == speaker]\n",
    "# for i in range(20):\n",
    "#     data_seq, digits = create_digit_sequence(data_george)\n",
    "#     print(\"Digits: {}\".format(digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f453d4",
   "metadata": {},
   "source": [
    "### Create \"meta\" HMM\n",
    "\n",
    "4.1 Combine the previously trained HMMs to a single \"meta\" HMM, altering the transition probabilities to make a circular graph that allows each word to follow another.\n",
    "\n",
    "4.2 Implement a method that converts a state sequence relating to the meta HMM into a sequence of actual digits.\n",
    "\n",
    "4.3 Decode your test sequences and compute the [word error rate](https://en.wikipedia.org/wiki/Word_error_rate) (WER) with [JiWER](https://pypi.org/project/jiwer/) (install the package in your working environment).\n",
    "\n",
    "4.4 Compute an overall WER; ie. over the cross-validation.\n",
    "\n",
    "4.5 (Optional) Implement a basic time-synchronous beam search; how do the results compare to the above viterbi decoding in terms of accuracy and time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
